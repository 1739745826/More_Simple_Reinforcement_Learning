{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAC的简化版实现,alpha使用常量代替.只使用一个value模型,而不是两个."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "#定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        over = terminated or truncated\n",
    "\n",
    "        #限制最大步数\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            over = True\n",
    "\n",
    "        return state, reward, over\n",
    "\n",
    "    #打印游戏图像\n",
    "    def show(self):\n",
    "        from matplotlib import pyplot as plt\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(self.env.render())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()\n",
    "\n",
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4698, 0.5302],\n",
       "        [0.4947, 0.5053]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_action = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    "    torch.nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "model_action(torch.randn(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0394, 0.0585],\n",
       "        [0.0586, 0.0380]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_value = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value_next = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value_next.load_state_dict(model_value.state_dict())\n",
    "\n",
    "model_value(torch.randn(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/rl/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import random\n",
    "\n",
    "\n",
    "#玩一局游戏并记录数据\n",
    "def play(show=False):\n",
    "    data = []\n",
    "    reward_sum = 0\n",
    "\n",
    "    state = env.reset()\n",
    "    over = False\n",
    "    while not over:\n",
    "        prob = model_action(torch.FloatTensor(state).reshape(1, 4))[0].tolist()\n",
    "        action = random.choices(range(2), weights=prob, k=1)[0]\n",
    "\n",
    "        next_state, reward, over = env.step(action)\n",
    "\n",
    "        data.append((state, action, reward, next_state, over))\n",
    "        reward_sum += reward\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if show:\n",
    "            display.clear_output(wait=True)\n",
    "            env.show()\n",
    "\n",
    "    return data, reward_sum\n",
    "\n",
    "\n",
    "play()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6002/3891364554.py:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  state = torch.FloatTensor([i[0] for i in data]).reshape(-1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(223,\n",
       " (array([ 0.01138922, -0.00029995,  0.00196026, -0.0162883 ], dtype=float32),\n",
       "  1,\n",
       "  1.0,\n",
       "  array([ 0.01138322,  0.19479384,  0.0016345 , -0.3083521 ], dtype=float32),\n",
       "  False))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据池\n",
    "class Pool:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pool = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pool)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.pool[i]\n",
    "\n",
    "    #更新动作池\n",
    "    def update(self):\n",
    "        #每次更新不少于N条新数据\n",
    "        old_len = len(self.pool)\n",
    "        while len(pool) - old_len < 200:\n",
    "            self.pool.extend(play()[0])\n",
    "\n",
    "        #只保留最新的N条数据\n",
    "        self.pool = self.pool[-2_0000:]\n",
    "\n",
    "    #获取一批数据样本\n",
    "    def sample(self):\n",
    "        data = random.sample(self.pool, 64)\n",
    "\n",
    "        state = torch.FloatTensor([i[0] for i in data]).reshape(-1, 4)\n",
    "        action = torch.LongTensor([i[1] for i in data]).reshape(-1, 1)\n",
    "        reward = torch.FloatTensor([i[2] for i in data]).reshape(-1, 1)\n",
    "        next_state = torch.FloatTensor([i[3] for i in data]).reshape(-1, 4)\n",
    "        over = torch.LongTensor([i[4] for i in data]).reshape(-1, 1)\n",
    "\n",
    "        return state, action, reward, next_state, over\n",
    "\n",
    "\n",
    "pool = Pool()\n",
    "pool.update()\n",
    "state, action, reward, next_state, over = pool.sample()\n",
    "\n",
    "len(pool), pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_action = torch.optim.Adam(model_action.parameters(), lr=2e-4)\n",
    "optimizer_value = torch.optim.Adam(model_value.parameters(), lr=2e-3)\n",
    "\n",
    "\n",
    "def soft_update(_from, _to):\n",
    "    for _from, _to in zip(_from.parameters(), _to.parameters()):\n",
    "        value = _to.data * 0.995 + _from.data * 0.005\n",
    "        _to.data.copy_(value)\n",
    "\n",
    "\n",
    "def get_prob_entropy(state):\n",
    "    prob = model_action(torch.FloatTensor(state).reshape(-1, 4))\n",
    "    entropy = prob * (prob + 1e-8).log()\n",
    "    entropy = -entropy.sum(dim=1, keepdim=True)\n",
    "\n",
    "    return prob, entropy\n",
    "\n",
    "\n",
    "def requires_grad(model, value):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.003380298614502"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_value(state, action, reward, next_state, over):\n",
    "    requires_grad(model_value, True)\n",
    "    requires_grad(model_action, False)\n",
    "\n",
    "    #计算target\n",
    "    with torch.no_grad():\n",
    "        #计算动作的熵\n",
    "        prob, entropy = get_prob_entropy(next_state)\n",
    "        target = model_value_next(next_state)\n",
    "\n",
    "    #加权熵,熵越大越好\n",
    "    target = (prob * target).sum(dim=1, keepdim=True)\n",
    "    target = target + 1e-3 * entropy\n",
    "    target = target * 0.98 * (1 - over) + reward\n",
    "\n",
    "    #计算value\n",
    "    value = model_value(state).gather(dim=1, index=action)\n",
    "    loss = torch.nn.functional.mse_loss(value, target)\n",
    "    loss.backward()\n",
    "    optimizer_value.step()\n",
    "    optimizer_value.zero_grad()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "train_value(state, action, reward, next_state, over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06116258352994919"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_action(state):\n",
    "    requires_grad(model_value, False)\n",
    "    requires_grad(model_action, True)\n",
    "\n",
    "    #计算熵\n",
    "    prob, entropy = get_prob_entropy(state)\n",
    "\n",
    "    #计算value\n",
    "    value = model_value(state)\n",
    "\n",
    "    #求期望求和\n",
    "    value = (prob * value).sum(dim=1, keepdim=True)\n",
    "\n",
    "    #加权熵\n",
    "    loss = -(value + 1e-3 * entropy).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_action.step()\n",
    "    optimizer_action.zero_grad()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "train_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OHoSU6uI-xIt",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 428 11.1\n",
      "10 2577 182.25\n",
      "20 5248 139.15\n",
      "30 7842 134.15\n",
      "40 10673 133.9\n",
      "50 13204 125.8\n",
      "60 15715 117.8\n",
      "70 18036 107.3\n",
      "80 20000 115.0\n",
      "90 20000 172.1\n",
      "100 20000 190.85\n",
      "110 20000 194.55\n",
      "120 20000 180.1\n",
      "130 20000 189.3\n",
      "140 20000 199.75\n",
      "150 20000 195.3\n",
      "160 20000 175.4\n",
      "170 20000 190.9\n",
      "180 20000 191.5\n",
      "190 20000 145.3\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model_action.train()\n",
    "    model_value.train()\n",
    "\n",
    "    #训练N次\n",
    "    for epoch in range(200):\n",
    "        #更新N条数据\n",
    "        pool.update()\n",
    "\n",
    "        #每次更新过数据后,学习N次\n",
    "        for i in range(200):\n",
    "            #采样一批数据\n",
    "            state, action, reward, next_state, over = pool.sample()\n",
    "\n",
    "            #训练\n",
    "            train_value(state, action, reward, next_state, over)\n",
    "            train_action(state)\n",
    "            soft_update(model_value, model_value_next)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_result = sum([play()[-1] for _ in range(20)]) / 20\n",
    "            print(epoch, len(pool), test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "154.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(True)[-1]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第7章-DQN算法.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:rl]",
   "language": "python",
   "name": "conda-env-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
