{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大化动作的熵,增强模型的稳定性\n",
    "\n",
    "Q(state,action) + alpha * 熵\\[Q(static,*)\\]\n",
    "\n",
    "训练过程中alpha应该递减.\n",
    "\n",
    "为了缓解自举,会用两个value模型评估Q函数,取其中小的值."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "#定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        over = terminated or truncated\n",
    "\n",
    "        #限制最大步数\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            over = True\n",
    "\n",
    "        return state, reward, over\n",
    "\n",
    "    #打印游戏图像\n",
    "    def show(self):\n",
    "        from matplotlib import pyplot as plt\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(self.env.render())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()\n",
    "\n",
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5400, 0.4600],\n",
       "        [0.5383, 0.4617]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_action = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    "    torch.nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "model_action(torch.randn(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3225,  0.1535],\n",
       "        [-0.2011,  0.3146]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_value1 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value1_next = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value2_next = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")\n",
    "\n",
    "model_value1_next.load_state_dict(model_value1.state_dict())\n",
    "model_value2_next.load_state_dict(model_value2.state_dict())\n",
    "\n",
    "model_value1(torch.randn(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/rl/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import random\n",
    "\n",
    "\n",
    "#玩一局游戏并记录数据\n",
    "def play(show=False):\n",
    "    data = []\n",
    "    reward_sum = 0\n",
    "\n",
    "    state = env.reset()\n",
    "    over = False\n",
    "    while not over:\n",
    "        prob = model_action(torch.FloatTensor(state).reshape(1, 4))[0].tolist()\n",
    "        action = random.choices(range(2), weights=prob, k=1)[0]\n",
    "\n",
    "        next_state, reward, over = env.step(action)\n",
    "\n",
    "        data.append((state, action, reward, next_state, over))\n",
    "        reward_sum += reward\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if show:\n",
    "            display.clear_output(wait=True)\n",
    "            env.show()\n",
    "\n",
    "    return data, reward_sum\n",
    "\n",
    "\n",
    "play()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6165/3891364554.py:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  state = torch.FloatTensor([i[0] for i in data]).reshape(-1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(207,\n",
       " (array([-0.009456  ,  0.01962566,  0.02216557,  0.02975623], dtype=float32),\n",
       "  1,\n",
       "  1.0,\n",
       "  array([-0.00906349,  0.21442285,  0.0227607 , -0.25585163], dtype=float32),\n",
       "  False))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据池\n",
    "class Pool:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pool = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pool)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.pool[i]\n",
    "\n",
    "    #更新动作池\n",
    "    def update(self):\n",
    "        #每次更新不少于N条新数据\n",
    "        old_len = len(self.pool)\n",
    "        while len(pool) - old_len < 200:\n",
    "            self.pool.extend(play()[0])\n",
    "\n",
    "        #只保留最新的N条数据\n",
    "        self.pool = self.pool[-2_0000:]\n",
    "\n",
    "    #获取一批数据样本\n",
    "    def sample(self):\n",
    "        data = random.sample(self.pool, 64)\n",
    "\n",
    "        state = torch.FloatTensor([i[0] for i in data]).reshape(-1, 4)\n",
    "        action = torch.LongTensor([i[1] for i in data]).reshape(-1, 1)\n",
    "        reward = torch.FloatTensor([i[2] for i in data]).reshape(-1, 1)\n",
    "        next_state = torch.FloatTensor([i[3] for i in data]).reshape(-1, 4)\n",
    "        over = torch.LongTensor([i[4] for i in data]).reshape(-1, 1)\n",
    "\n",
    "        return state, action, reward, next_state, over\n",
    "\n",
    "\n",
    "pool = Pool()\n",
    "pool.update()\n",
    "state, action, reward, next_state, over = pool.sample()\n",
    "\n",
    "len(pool), pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_action = torch.optim.Adam(model_action.parameters(), lr=2e-4)\n",
    "optimizer_value1 = torch.optim.Adam(model_value1.parameters(), lr=2e-3)\n",
    "optimizer_value2 = torch.optim.Adam(model_value2.parameters(), lr=2e-3)\n",
    "\n",
    "\n",
    "def soft_update(_from, _to):\n",
    "    for _from, _to in zip(_from.parameters(), _to.parameters()):\n",
    "        value = _to.data * 0.995 + _from.data * 0.005\n",
    "        _to.data.copy_(value)\n",
    "\n",
    "\n",
    "def get_prob_entropy(state):\n",
    "    prob = model_action(torch.FloatTensor(state).reshape(-1, 4))\n",
    "    entropy = prob * (prob + 1e-8).log()\n",
    "    entropy = -entropy.sum(dim=1, keepdim=True)\n",
    "\n",
    "    return prob, entropy\n",
    "\n",
    "\n",
    "def requires_grad(model, value):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(value)\n",
    "\n",
    "\n",
    "alpha = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7929240465164185"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_value(state, action, reward, next_state, over):\n",
    "    requires_grad(model_value1, True)\n",
    "    requires_grad(model_value2, True)\n",
    "    requires_grad(model_action, False)\n",
    "\n",
    "    #计算target\n",
    "    with torch.no_grad():\n",
    "        #计算动作的熵\n",
    "        prob, entropy = get_prob_entropy(next_state)\n",
    "        target1 = model_value1_next(next_state)\n",
    "        target2 = model_value2_next(next_state)\n",
    "        target = torch.min(target1, target2)\n",
    "\n",
    "    #加权熵,熵越大越好\n",
    "    target = (prob * target).sum(dim=1, keepdim=True)\n",
    "    #target = target + alpha * entropy\n",
    "    target = target * 0.98 * (1 - over) + reward\n",
    "\n",
    "    #计算value\n",
    "    value = model_value1(state).gather(dim=1, index=action)\n",
    "    loss = torch.nn.functional.mse_loss(value, target)\n",
    "    loss.backward()\n",
    "    optimizer_value1.step()\n",
    "    optimizer_value1.zero_grad()\n",
    "\n",
    "    value = model_value2(state).gather(dim=1, index=action)\n",
    "    loss = torch.nn.functional.mse_loss(value, target)\n",
    "    loss.backward()\n",
    "    optimizer_value2.step()\n",
    "    optimizer_value2.zero_grad()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "train_value(state, action, reward, next_state, over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.3504273891448975"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_action(state):\n",
    "    requires_grad(model_value1, False)\n",
    "    requires_grad(model_value2, False)\n",
    "    requires_grad(model_action, True)\n",
    "\n",
    "    #计算熵\n",
    "    prob, entropy = get_prob_entropy(state)\n",
    "\n",
    "    #计算value\n",
    "    value1 = model_value1(state)\n",
    "    value2 = model_value2(state)\n",
    "    value = torch.min(value1, value2)\n",
    "\n",
    "    #求期望求和\n",
    "    value = (prob * value).sum(dim=1, keepdim=True)\n",
    "\n",
    "    #加权熵\n",
    "    loss = -(value + alpha * entropy).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_action.step()\n",
    "    optimizer_action.zero_grad()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "train_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OHoSU6uI-xIt",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 415 4.85 24.65\n",
      "10 2588 3.5765070154404013 40.4\n",
      "20 4887 2.637402563194723 90.15\n",
      "30 7471 1.944884282434314 120.9\n",
      "40 10401 1.4342045938857926 152.55\n",
      "50 13384 1.0576170704349255 158.3\n",
      "60 16011 0.7799123447546468 168.95\n",
      "70 18661 0.5751261798852716 189.55\n",
      "80 20000 0.4241119210563118 181.0\n",
      "90 20000 0.3127503630906814 195.45\n",
      "100 20000 0.23062966343821745 200.0\n",
      "110 20000 0.17007187819699862 200.0\n",
      "120 20000 0.12541510628880226 200.0\n",
      "130 20000 0.0924841252544546 200.0\n",
      "140 20000 0.06820002531740733 200.0\n",
      "150 20000 0.05029234412390111 200.0\n",
      "160 20000 0.03708678795506704 200.0\n",
      "170 20000 0.027348692227102643 200.0\n",
      "180 20000 0.020167585487289277 200.0\n",
      "190 20000 0.014872064119543118 200.0\n",
      "200 20000 0.01096701889847947 200.0\n",
      "210 20000 0.008087344335851402 112.3\n",
      "220 20000 0.005963802835763862 168.5\n",
      "230 20000 0.004397852099136662 200.0\n",
      "240 20000 0.00324308224441888 200.0\n",
      "250 20000 0.0023915270925390364 200.0\n",
      "260 20000 0.0017635697781611648 199.4\n",
      "270 20000 0.001300498903878779 176.3\n",
      "280 20000 0.00095901926872062 158.8\n",
      "290 20000 0.0007072039469117156 200.0\n",
      "300 20000 0.0005215092530880188 181.85\n",
      "310 20000 0.00038457350562605836 200.0\n",
      "320 20000 0.00028359378161321784 196.6\n",
      "330 20000 0.00020912889679895809 200.0\n",
      "340 20000 0.00015421669413047116 198.5\n",
      "350 20000 0.00011372311102178491 199.95\n",
      "360 20000 8.386216585301472e-05 174.95\n",
      "370 20000 6.184198443367701e-05 193.4\n",
      "380 20000 4.5603771376454e-05 192.35\n",
      "390 20000 3.3629321290397505e-05 155.65\n",
      "400 20000 2.479907289064039e-05 197.4\n",
      "410 20000 1.828743467418417e-05 172.1\n",
      "420 20000 1.3485595547758294e-05 178.75\n",
      "430 20000 9.944603522463789e-06 199.65\n",
      "440 20000 7.333390569869087e-06 198.05\n",
      "450 20000 5.407819138165211e-06 199.5\n",
      "460 20000 3.987856306367163e-06 186.55\n",
      "470 20000 2.940741454905237e-06 189.3\n",
      "480 20000 2.1685736998072146e-06 199.5\n",
      "490 20000 1.5991585671876392e-06 200.0\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    global alpha\n",
    "    model_action.train()\n",
    "    model_value1.train()\n",
    "    model_value2.train()\n",
    "\n",
    "    #训练N次\n",
    "    for epoch in range(500):\n",
    "        #更新N条数据\n",
    "        pool.update()\n",
    "\n",
    "        #每次更新过数据后,学习N次\n",
    "        for i in range(200):\n",
    "            #采样一批数据\n",
    "            state, action, reward, next_state, over = pool.sample()\n",
    "\n",
    "            #训练\n",
    "            train_value(state, action, reward, next_state, over)\n",
    "            train_action(state)\n",
    "            soft_update(model_value1, model_value1_next)\n",
    "            soft_update(model_value2, model_value2_next)\n",
    "\n",
    "        alpha *= 0.97\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_result = sum([play()[-1] for _ in range(20)]) / 20\n",
    "            print(epoch, len(pool), alpha, test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASAAAADMCAYAAADTcn7NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAUEUlEQVR4nO3dbWxT970H8K9PEjvk4TiENHajxCLSekcjHrYFSE4rbbutS9ZFU2kj3W5CXVYhqjIHlWZCaqRCBepVENNVOzYaXkyDvmhHbzaxqbm0VRTaoAlDSrrchRSiVYKbCGK7wHwcUmIn9u++6HJWQ0LzhP9x8v1IR6r//198fudQf3V8jn1sExEBEZECmuoGiGjpYgARkTIMICJShgFERMowgIhIGQYQESnDACIiZRhARKQMA4iIlGEAEZEyygLo0KFDWLlyJbKzs1FVVYWuri5VrRCRIkoC6J133kFjYyNeeeUVfPLJJ1i3bh1qamoQCoVUtENEithUfBm1qqoKGzZswG9+8xsAQCKRQFlZGXbs2IGXXnop1e0QkSKZqV5hLBZDd3c3mpqarDFN0+D1euH3+yf9m2g0img0aj1OJBK4ceMGVqxYAZvNds97JqKZEREMDw+jpKQEmjb1G62UB9C1a9cQj8fhcrmSxl0uFy5evDjp3zQ3N2Pv3r2paI+I5tHg4CBKS0unnE95AM1GU1MTGhsbrcemacLj8WBwcBC6rivsjIgmE4lEUFZWhvz8/LvWpTyAioqKkJGRgWAwmDQeDAbhdrsn/RuHwwGHw3HHuK7rDCCiBezrTpGk/CqY3W5HZWUlOjo6rLFEIoGOjg4YhpHqdohIISVvwRobG1FfX4/169dj48aNeP311zEyMoJnn31WRTtEpIiSAHr66afx+eefY8+ePQgEAvjWt76F999//44T00S0uCn5HNBcRSIROJ1OmKbJc0BEC9B0X6P8LhgRKcMAIiJlGEBEpAwDiIiUYQARkTIMICJShgFERMowgIhIGQYQESnDACIiZRhARKQMA4iIlGEAEZEyDCAiUoYBRETKMICISBkGEBEpwwAiImUYQESkDAOIiJRhABGRMgwgIlKGAUREyjCAiEgZBhARKcMAIiJlGEBEpAwDiIiUmXEAnTp1Cj/60Y9QUlICm82GP/3pT0nzIoI9e/bg/vvvx7Jly+D1evH3v/89qebGjRvYsmULdF1HQUEBtm7dips3b85pQ4go/cw4gEZGRrBu3TocOnRo0vkDBw7g4MGDOHz4MM6ePYvc3FzU1NRgdHTUqtmyZQv6+vrQ3t6OtrY2nDp1Cs8999zst4KI0pPMAQA5fvy49TiRSIjb7ZZf/vKX1lg4HBaHwyG///3vRUTk008/FQDy8ccfWzXvvfee2Gw2uXLlyrTWa5qmABDTNOfSPhHdI9N9jc7rOaBLly4hEAjA6/VaY06nE1VVVfD7/QAAv9+PgoICrF+/3qrxer3QNA1nz56d9Hmj0SgikUjSQkTpb14DKBAIAABcLlfSuMvlsuYCgQCKi4uT5jMzM1FYWGjV3K65uRlOp9NaysrK5rNtIlIkLa6CNTU1wTRNaxkcHFTdEhHNg3kNILfbDQAIBoNJ48Fg0Jpzu90IhUJJ8+Pj47hx44ZVczuHwwFd15MWIkp/8xpA5eXlcLvd6OjosMYikQjOnj0LwzAAAIZhIBwOo7u726o5efIkEokEqqqq5rMdIlrgMmf6Bzdv3sRnn31mPb506RJ6enpQWFgIj8eDnTt34tVXX8UDDzyA8vJy7N69GyUlJdi8eTMA4MEHH8QPfvADbNu2DYcPH8bY2BgaGhrw4x//GCUlJfO2YUSUBmZ6ee3DDz8UAHcs9fX1IvLlpfjdu3eLy+USh8Mhjz76qPT39yc9x/Xr1+UnP/mJ5OXlia7r8uyzz8rw8PC8X+IjIjWm+xq1iYgozL9ZiUQicDqdME2T54OIFqDpvkbT4ioYES1ODCAiUoYBRETKMICISBkGEBEpwwAiImUYQESkDAOIiJRhABGRMgwgIlKGAUREyjCAiEgZBhARKcMAIiJlGEBEpAwDiIiUYQARkTIMICJShgFERMowgIhImRn/LA8RpTeRBMyB84jHblljufethMNZDJvNltJeGEBES4wk4hg880eMhoessbKHnobL+UjKe+FbMCKCxMeUrJcBRERIxMeVrJcBRESQcR4BEZEiCb4FI6LUsEHLzEoaice+UNIJA4hoibHZNGQX3J80dusfQ4BIynuZUQA1Nzdjw4YNyM/PR3FxMTZv3oz+/v6kmtHRUfh8PqxYsQJ5eXmoq6tDMBhMqhkYGEBtbS1ycnJQXFyMXbt2YXxczUkwoqXo9iMgFeEDzDCAOjs74fP5cObMGbS3t2NsbAybNm3CyMiIVfPiiy/i3XffRWtrKzo7O3H16lU89dRT1nw8HkdtbS1isRhOnz6NN998E0ePHsWePXvmb6uIaGo2QMvI+vq6VJA5CIVCAkA6OztFRCQcDktWVpa0trZaNRcuXBAA4vf7RUTkxIkTommaBAIBq6alpUV0XZdoNDqt9ZqmKQDENM25tE+0JCUSCfm/0/8tXYe3WUvfH/9TEvH4vK1juq/ROZ0DMk0TAFBYWAgA6O7uxtjYGLxer1WzatUqeDwe+P1+AIDf78eaNWvgcrmsmpqaGkQiEfT19U26nmg0ikgkkrQQ0ewtlCOgWQdQIpHAzp078fDDD2P16tUAgEAgALvdjoKCgqRal8uFQCBg1Xw1fCbmJ+Ym09zcDKfTaS1lZWWzbZuIAGgZC+NbWLMOIJ/Ph/Pnz+PYsWPz2c+kmpqaYJqmtQwODt7zdRItVjabDdCSX/oiApFEynuZVQw2NDSgra0Np06dQmlpqTXudrsRi8UQDoeTjoKCwSDcbrdV09XVlfR8E1fJJmpu53A44HA4ZtMqEU2DSBxQEEAzOgISETQ0NOD48eM4efIkysvLk+YrKyuRlZWFjo4Oa6y/vx8DAwMwDAMAYBgGent7EQqFrJr29nbouo6Kioq5bAsRzZIkEpDEAj8C8vl8ePvtt/HnP/8Z+fn51jkbp9OJZcuWwel0YuvWrWhsbERhYSF0XceOHTtgGAaqq6sBAJs2bUJFRQWeeeYZHDhwAIFAAC+//DJ8Ph+PcohUScS/PApKsRkFUEtLCwDg+9//ftL4kSNH8LOf/QwA8Nprr0HTNNTV1SEajaKmpgZvvPGGVZuRkYG2tjZs374dhmEgNzcX9fX12Ldv39y2hIhmTUTNEZBNRNFHIOcgEonA6XTCNE3ouq66HaK0E/hbOwb9rdbjrJwCPPjkS3DkFc7L80/3NcrvghEtQdlON2xahvV47FYE47eGU94HA4hoCdIys4A77v+8wL+MSkSLgy0jE0Bqb0A/GQYQ0RKU9p+EJqL0ZcvISvlP8EyGAUS0BGkaj4CISBGbpuH2c0AqPgfEACIiAKLkp3kYQEQEQM2PEzKAiAiAmp/mYQARESAMICJSSBT8Mg0DiGgJ0rKWwZ5b8JURwWh4KPV9pHyNRKSclpEJzZ6dNBYfi6a+j5SvkYjUs9kWxIcRGUBES5BN05Jux6EKA4hoCbLZNNgyGEBEpILNBtskb8FSfYNUBhDRkmSDzXb7b4Pxu2BEpIjEx5HquyIygIgIACCJ8ZTflZUBREQA8M9vw/MIiIgUkPg4T0ITkRqJxDiQ4gBS/1FIIronEokEhoeHpzyqEYcz6fFoOITwP65Dy8qetD4zMxO5ubnzei9pBhDRInXlyhV4vV6MjIxMOv9EdTnqvQ9ajwNXB/EfhoGR0clvy/Hd734Xb7311rz2yAAiWqTi8TiuXr2KmzdvTjr/+fUCXBsrxeVba+DQvkDB2CkMDV3F8BexSeuvXbs27z3O6BxQS0sL1q5dC13Xoes6DMPAe++9Z82Pjo7C5/NhxYoVyMvLQ11dHYLBYNJzDAwMoLa2Fjk5OSguLsauXbswruA+JERL3ee3luN/hx/BtbEyXIn+G/42/O+IS1ZKe5hRAJWWlmL//v3o7u7GuXPn8Mgjj+CJJ55AX18fAODFF1/Eu+++i9bWVnR2duLq1at46qmnrL+Px+Oora1FLBbD6dOn8eabb+Lo0aPYs2fP/G4VEX2tSNSBWMLxz0c2jMSdSEiKr0vJHC1fvlx++9vfSjgclqysLGltbbXmLly4IADE7/eLiMiJEydE0zQJBAJWTUtLi+i6LtFodNrrNE1TAIhpmnNtn2jRunTpkuTl5Qm+/HDPHctD61bL6/v/R/a+2iX7Xj0j/7X7oOQty56y/rHHHpNEIjGtdU/3NTrrc0DxeBytra0YGRmBYRjo7u7G2NgYvF6vVbNq1Sp4PB74/X5UV1fD7/djzZo1cLlcVk1NTQ22b9+Ovr4+fPvb355RDxcvXkReXt5sN4FoUbty5QoSd/mtr8GhAfg7XkUwthJ22yjy5TPExqa+L/TIyAguXLgwrXVPdd7pdjMOoN7eXhiGgdHRUeTl5eH48eOoqKhAT08P7HY7CgoKkupdLhcCgQAAIBAIJIXPxPzE3FSi0Sii0X/drS0SiQAATNPk+SOiKdztEjwADIYieKfdD8A/recbHx9HOByeVu1UV95uN+MA+uY3v4menh6Ypok//OEPqK+vR2dn50yfZkaam5uxd+/eO8arqqqg6/o9XTdRurp8+TIy5vGeP06nE4ZhTOtzQBMHCV9nxmec7HY7vvGNb6CyshLNzc1Yt24dfvWrX8HtdiMWi92RkMFgEG63GwDgdrvvuCo28XiiZjJNTU0wTdNaBgcHZ9o2ES1Acz7lnUgkEI1GUVlZiaysLHR0dFhz/f39GBgYgGEYAADDMNDb24tQKGTVtLe3Q9d1VFRUTLkOh8NhXfqfWIgo/c3oLVhTUxMef/xxeDweDA8P4+2338ZHH32EDz74AE6nE1u3bkVjYyMKCwuh6zp27NgBwzBQXV0NANi0aRMqKirwzDPP4MCBAwgEAnj55Zfh8/ngcDi+Zu1EtNjMKIBCoRB++tOfYmhoCE6nE2vXrsUHH3yAxx57DADw2muvQdM01NXVIRqNoqamBm+88Yb19xkZGWhra8P27dthGAZyc3NRX1+Pffv2ze9WERE0TYOu69C0+flsT25u7rw8z1fZ5G6nyReoSCQCp9MJ0zT5doxoCuPj4wgEAvN2i43s7GwUFRVN+yT0dF6j/C4Y0SKVmZmJ0tJS1W3cFe8HRETKMICISBkGEBEpwwAiImUYQESkDAOIiJRhABGRMgwgIlKGAUREyjCAiEgZBhARKcMAIiJlGEBEpAwDiIiUYQARkTIMICJShgFERMowgIhIGQYQESnDACIiZRhARKQMA4iIlGEAEZEyDCAiUoYBRETKMICISBkGEBEpwwAiImUYQESkDAOIiJTJVN3AbIgIACASiSjuhIgmM/HanHitTiUtA+j69esAgLKyMsWdENHdDA8Pw+l0TjmflgFUWFgIABgYGLjrxlGySCSCsrIyDA4OQtd11e2kBe6z2RERDA8Po6Sk5K51aRlAmvblqSun08n/KWZB13XutxniPpu56Rwc8CQ0ESnDACIiZdIygBwOB1555RU4HA7VraQV7reZ4z67t2zyddfJiIjukbQ8AiKixYEBRETKMICISBkGEBEpk5YBdOjQIaxcuRLZ2dmoqqpCV1eX6paUaW5uxoYNG5Cfn4/i4mJs3rwZ/f39STWjo6Pw+XxYsWIF8vLyUFdXh2AwmFQzMDCA2tpa5OTkoLi4GLt27cL4+HgqN0WZ/fv3w2azYefOndYY91mKSJo5duyY2O12+d3vfid9fX2ybds2KSgokGAwqLo1JWpqauTIkSNy/vx56enpkR/+8Ifi8Xjk5s2bVs3zzz8vZWVl0tHRIefOnZPq6mp56KGHrPnx8XFZvXq1eL1e+etf/yonTpyQoqIiaWpqUrFJKdXV1SUrV66UtWvXygsvvGCNc5+lRtoF0MaNG8Xn81mP4/G4lJSUSHNzs8KuFo5QKCQApLOzU0REwuGwZGVlSWtrq1Vz4cIFASB+v19ERE6cOCGapkkgELBqWlpaRNd1iUajqd2AFBoeHpYHHnhA2tvb5Xvf+54VQNxnqZNWb8FisRi6u7vh9XqtMU3T4PV64ff7FXa2cJimCeBfX9jt7u7G2NhY0j5btWoVPB6Ptc/8fj/WrFkDl8tl1dTU1CASiaCvry+F3aeWz+dDbW1t0r4BuM9SKa2+jHrt2jXE4/Gkf3QAcLlcuHjxoqKuFo5EIoGdO3fi4YcfxurVqwEAgUAAdrsdBQUFSbUulwuBQMCqmWyfTswtRseOHcMnn3yCjz/++I457rPUSasAorvz+Xw4f/48/vKXv6huZUEbHBzECy+8gPb2dmRnZ6tuZ0lLq7dgRUVFyMjIuONqRDAYhNvtVtTVwtDQ0IC2tjZ8+OGHKC0ttcbdbjdisRjC4XBS/Vf3mdvtnnSfTswtNt3d3QiFQvjOd76DzMxMZGZmorOzEwcPHkRmZiZcLhf3WYqkVQDZ7XZUVlaio6PDGkskEujo6IBhGAo7U0dE0NDQgOPHj+PkyZMoLy9Pmq+srERWVlbSPuvv78fAwIC1zwzDQG9vL0KhkFXT3t4OXddRUVGRmg1JoUcffRS9vb3o6emxlvXr12PLli3Wf3OfpYjqs+AzdezYMXE4HHL06FH59NNP5bnnnpOCgoKkqxFLyfbt28XpdMpHH30kQ0ND1vLFF19YNc8//7x4PB45efKknDt3TgzDEMMwrPmJS8qbNm2Snp4eef/99+W+++5bUpeUv3oVTIT7LFXSLoBERH7961+Lx+MRu90uGzdulDNnzqhuSRkAky5Hjhyxam7duiU///nPZfny5ZKTkyNPPvmkDA0NJT3P5cuX5fHHH5dly5ZJUVGR/OIXv5CxsbEUb406twcQ91lq8HYcRKRMWp0DIqLFhQFERMowgIhIGQYQESnDACIiZRhARKQMA4iIlGEAEZEyDCAiUoYBRETKMICISBkGEBEp8/+ju8st94aDVQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(True)[-1]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第7章-DQN算法.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:rl]",
   "language": "python",
   "name": "conda-env-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
